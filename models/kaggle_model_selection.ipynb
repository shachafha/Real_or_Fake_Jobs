{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bceab2cb-9dff-429e-87f1-3bfa1832cc93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sparknlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sparknlp.annotator import BertEmbeddings\n",
    "from pyspark.sql.types import StringType\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from pyspark.sql.functions import udf, explode\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "from pyspark.sql.functions import udf, array, concat, col\n",
    "from pyspark.ml.classification import RandomForestClassifier, GBTClassifier, LogisticRegression\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50a775f9-3a80-4777-ae71-1947bf83f60e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Preprocess kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9a0ac583-6f40-45c7-88ba-5244bdd60651",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('fake_job_postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e487ab8b-1473-4c24-8170-f98d4a52fd7e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load the gemini dataset\n",
    "gemini_data = pd.read_csv(\"fake_job_postings_with_AI.csv\")\n",
    "\n",
    "gemini_data[\"required_experience_gemini\"] = gemini_data[\"required_experience_gemini\"].replace(to_replace=[\"None\", \"None specified\"], value=None)\n",
    "gemini_data[\"required_education_gemini\"] = gemini_data[\"required_education_gemini\"].replace(to_replace=[\"None\", \"None specified\"], value=None)\n",
    "gemini_data[\"employment_type_gemini\"] = gemini_data[\"employment_type_gemini\"].replace(to_replace=[\"None\", \"None specified\"], value=None)\n",
    "gemini_data[\"requirements_gemini\"] = gemini_data[\"requirements_gemini\"].replace(to_replace=[\"None\", \"None specified\"], value=None)\n",
    "\n",
    "enriched_columns = [\"required_experience\", \"required_education\", \"employment_type\", \"requirements\", \"industry\", \"function\"]\n",
    "\n",
    "# Enrich the dataset with the gemini results\n",
    "for idx, job in gemini_data.iterrows():\n",
    "    rows_filter = df[\"job_id\"] == job[\"job_id\"]\n",
    "    original_job_idx = df.index[rows_filter][0]\n",
    "    original_job = df[rows_filter].loc[original_job_idx]\n",
    "\n",
    "    for c in enriched_columns:\n",
    "        if pd.isna(df.loc[original_job_idx, c]) and not pd.isna(gemini_data.loc[idx, f\"{c}_gemini\"]):\n",
    "            df.loc[original_job_idx, c] = job[f\"{c}_gemini\"]\n",
    "\n",
    "df[\"benefits\"] = df[\"benefits\"].replace(to_replace=[None], value=\"\")\n",
    "df[\"company_profile\"] = df[\"company_profile\"].replace(to_replace=[None], value=\"\")\n",
    "df[\"description\"] = df[\"description\"].replace(to_replace=[None], value=\"\")\n",
    "df[\"requirements\"] = df[\"requirements\"].replace(to_replace=[None], value=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "757bb045-f518-4861-9c1f-cad8ce183cf1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Select relevant columns for preprocessing\n",
    "df = df[['title', 'department', 'company_profile', 'description', 'requirements', 'benefits', 'employment_type', 'required_experience', 'required_education', 'industry', 'function', 'fraudulent']]\n",
    "\n",
    "# Replace missing values with empty strings\n",
    "for c in df.columns:\n",
    "    df[c].replace(pd.NA, '', inplace=True)\n",
    "    if pd.api.types.is_string_dtype(df[c]): \n",
    "        df[c] = df[c].str.lower()\n",
    "\n",
    "# Add word count features to specific columns\n",
    "count_cols = ['company_profile', 'description', 'requirements', 'benefits']\n",
    "for c in count_cols:\n",
    "    df[c + '_word_count'] = df[c].str.split().str.len()\n",
    "\n",
    "df['total_word_count'] = df.apply(lambda row: sum(row[c].split().__len__() for c in df.columns if isinstance(row[c], str)), axis=1)\n",
    "\n",
    "# Concatenate all text columns into a single column for embedding creation\n",
    "cols = ['title', 'department', 'company_profile', 'description', 'requirements', 'benefits', 'employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
    "df['all_text'] = df[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\n",
    "df = df[['all_text', 'company_profile_word_count', 'description_word_count', 'requirements_word_count', 'benefits_word_count', 'total_word_count', 'fraudulent']]\n",
    "processed_kaggle_dataset = df\n",
    "processed_kaggle_dataset.to_csv('processed_fake_job_postings.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e35fbe9-9f94-43b2-9d45-28db0bebbb13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create spark dataframe \n",
    "df = spark.createDataFrame(processed_kaggle_dataset)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aee6b181-42b1-4f24-84c4-6f1987adc9c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load pre-trained sentence transformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "# embed text using Sentence Transformer\n",
    "def embed_text(text):\n",
    "    return model.encode([text]).tolist()[0]  \n",
    "\n",
    "embed_udf = udf(embed_text, ArrayType(FloatType())) \n",
    "\n",
    "# Apply the UDF to the DataFrame\n",
    "df = df.withColumn(\"embeddings_vector\", embed_udf(\"all_text\"))\n",
    "\n",
    "# Normalize word count columns\n",
    "word_count_cols = [\"company_profile_word_count\", \"description_word_count\", \"requirements_word_count\", \"benefits_word_count\", \"total_word_count\"]\n",
    "for c in word_count_cols:\n",
    "    min_value = df.agg({f\"{c}\": \"min\"}).collect()[0][0]\n",
    "    max_value = df.agg({f\"{c}\": \"max\"}).collect()[0][0]\n",
    "    \n",
    "    df = df.withColumn(\n",
    "        f\"{c}_normalized\",\n",
    "        (col(c) -min_value) / (max_value - min_value)\n",
    "    )\n",
    "\n",
    "# Create a numeric array from the word count columns\n",
    "df = df.withColumn(\n",
    "    \"numeric_features_array\",\n",
    "    array(*[col(f\"{c}_normalized\") for c in word_count_cols])\n",
    ")\n",
    "\n",
    "\n",
    "# Concatenate the numeric array with embeddings_vector\n",
    "df = df.withColumn(\n",
    "    \"concatenated_features\",\n",
    "    concat(col(\"numeric_features_array\"), col(\"embeddings_vector\"))\n",
    "    )\n",
    "\n",
    "def array_to_vector(array):\n",
    "    return Vectors.dense(array)\n",
    "\n",
    "array_to_vector_udf = udf(array_to_vector, VectorUDT())\n",
    "\n",
    "# Convert embeddings column to DenseVector\n",
    "df = df.withColumn(\"features\", array_to_vector_udf(\"concatenated_features\"))\n",
    "display(df.limit(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "796ef081-bf1a-4523-bffc-3c3d47eb349a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "full_df = df\n",
    "df = df.select('features', 'fraudulent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "01112aa0-0477-4b65-b839-305bcf7278f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test models\n",
    "Train and test models on training and validation split that maintained the same class \n",
    "proportions to account for\n",
    "the imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07cf3389-5059-4dc0-b7a2-9bf4c51d7c36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Separate the non-fraudulent and fraudulent data\n",
    "non_fraud = df.filter(col(\"fraudulent\") == 0)\n",
    "fraud = df.filter(col(\"fraudulent\") == 1)\n",
    "\n",
    "# Split the data into training and validation sets, with label ratios similar to the original data (5% fraudulent and 95% non-fraudulent).\n",
    "train_non_fraud, val_non_fraud = non_fraud.randomSplit([0.8, 0.2], seed=42)\n",
    "train_fraud, val_fraud = fraud.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "train_df = train_non_fraud.union(train_fraud)\n",
    "val_df = val_non_fraud.union(val_fraud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "597b49e5-4146-4e82-8a78-a48b8288453b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: RandomForest\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ae2ad833394587ad770d70c8b25b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2c510f37b14d4e8a7aa0b3661f1fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result of Model RandomForest:\n  - AUC (ROC): 0.9350638511814978\n  - AUC (PR): 0.6730406208208748\n  - F1: 0.5217391304347826\n  - Balanced Accuracy: 0.6795475113122171\nModel: GBTClassifier\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961963a473ab4ae197b49b27d4f82f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c01731d200c46dba5b194221cbd3524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result of Model GBTClassifier:\n  - AUC (ROC): 0.9477516339869297\n  - AUC (PR): 0.6854486604991734\n  - F1: 0.6044776119402985\n  - Balanced Accuracy: 0.7644193061840121\nModel: LogisticRegression\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb39f915ec54774a8014a3872463107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "230ca6016c8b42b99368562e7682d079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result of Model LogisticRegression:\n  - AUC (ROC): 0.9146385118149828\n  - AUC (PR): 0.5656679716403981\n  - F1: 0.2598870056497175\n  - Balanced Accuracy: 0.5760633484162896\nModel: FFNetwork\nResult of Model FFNetwork:\n  - AUC (ROC): 0.835743589743589\n  - AUC (PR): 0.26424125673583426\n  - F1: 0\n  - Balanced Accuracy: 0.5\nResults for all models:\nRandomForest: AUC (ROC) = 0.9350638511814978, AUC (PR) = 0.6730406208208748, F1 = 0.5217391304347826, Balanced Accuracy = 0.6795475113122171\nGBTClassifier: AUC (ROC) = 0.9477516339869297, AUC (PR) = 0.6854486604991734, F1 = 0.6044776119402985, Balanced Accuracy = 0.7644193061840121\nLogisticRegression: AUC (ROC) = 0.9146385118149828, AUC (PR) = 0.5656679716403981, F1 = 0.2598870056497175, Balanced Accuracy = 0.5760633484162896\nFFNetwork: AUC (ROC) = 0.835743589743589, AUC (PR) = 0.26424125673583426, F1 = 0, Balanced Accuracy = 0.5\n"
     ]
    }
   ],
   "source": [
    "# Initialize evaluators\n",
    "evaluator_auc = BinaryClassificationEvaluator(labelCol=\"fraudulent\", metricName=\"areaUnderROC\")\n",
    "evaluator_pr = BinaryClassificationEvaluator(labelCol=\"fraudulent\", metricName=\"areaUnderPR\")\n",
    "results = {}\n",
    "\n",
    "# Define classifiers dictionary with parameters directly\n",
    "classifiers = {\n",
    "    \"RandomForest\": RandomForestClassifier(labelCol=\"fraudulent\", featuresCol=\"features\", maxDepth=10, numTrees=10, seed=1),\n",
    "    \"GBTClassifier\": GBTClassifier(labelCol=\"fraudulent\", featuresCol=\"features\", maxDepth=10, maxIter=10, seed=1),\n",
    "    \"LogisticRegression\": LogisticRegression(labelCol=\"fraudulent\", featuresCol=\"features\", regParam=0.1, maxIter=10),\n",
    "    \"FFNetwork\": MultilayerPerceptronClassifier(labelCol=\"fraudulent\", featuresCol=\"features\", layers=[389, 32, 2], maxIter=6, seed=1)\n",
    "}\n",
    "\n",
    "# Train and evaluate the models\n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"Model: {name}\")\n",
    "\n",
    "    model = classifier.fit(train_df)\n",
    "    predictions = model.transform(val_df)\n",
    "    \n",
    "    # Compute AUC-ROC\n",
    "    auc_score = evaluator_auc.evaluate(predictions)\n",
    "    \n",
    "    # Compute AUC-PR\n",
    "    pr_score = evaluator_pr.evaluate(predictions)\n",
    "    \n",
    "    # Compute F1 score manually\n",
    "    tp = predictions.filter((predictions[\"prediction\"] == 1) & (predictions[\"fraudulent\"] == 1)).count()\n",
    "    fp = predictions.filter((predictions[\"prediction\"] == 1) & (predictions[\"fraudulent\"] == 0)).count()\n",
    "    fn = predictions.filter((predictions[\"prediction\"] == 0) & (predictions[\"fraudulent\"] == 1)).count()\n",
    "    tn = predictions.filter((predictions[\"prediction\"] == 0) & (predictions[\"fraudulent\"] == 0)).count()\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    tnr = tn / (tn + fp) if (tn + fp) > 0 else 0  \n",
    "    # Compute Balanced Accuracy\n",
    "    balanced_accuracy = (recall + tnr) / 2  \n",
    "\n",
    "    results[name] = {\n",
    "        \"auc\": auc_score,\n",
    "        \"pr\": pr_score,\n",
    "        \"f1\": f1_score,\n",
    "        \"balanced_accuracy\": balanced_accuracy\n",
    "    }\n",
    "\n",
    "    print(f\"Result of Model {name}:\")\n",
    "    print(f\"  - AUC (ROC): {auc_score}\")\n",
    "    print(f\"  - AUC (PR): {pr_score}\")\n",
    "    print(f\"  - F1: {f1_score}\")\n",
    "    print(f\"  - Balanced Accuracy: {balanced_accuracy}\")\n",
    "\n",
    "# Print out the results for all models\n",
    "print(\"Results for all models:\")\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}: AUC (ROC) = {result['auc']}, AUC (PR) = {result['pr']}, F1 = {result['f1']}, Balanced Accuracy = {result['balanced_accuracy']}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "kaggle_model_selection",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
